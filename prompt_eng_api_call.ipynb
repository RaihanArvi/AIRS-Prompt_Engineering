{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf1a2c-5c69-48ae-a537-76f4ed71fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95962ec-53d8-4e97-97fd-c45de0e7c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssessmentResultPerCriteria(BaseModel):\n",
    "    explanation: str = Field(..., description=\"A detailed reasoning that supports the decision, based on evidence from the document.\")\n",
    "    result: str = Field(..., description=\"The overall decision for this item. Respond only with one of ['yes', 'no'].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15526668-3989-4766-b023-74d2b1d2767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"\"\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fc0b4-14a4-461b-b102-21d1f012aeb0",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dd953-4715-4a56-ac85-d114972c9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_prompt = \"\"\"\n",
    "# Introduction and Role Setting:\n",
    "You are a systematic reviewer who is an expert in risk of bias assessment of papers in environmental policies. You are particularly good at learning evaluation criteria, and closely following it to assess the risk of bias of climate and energy studies.Â \n",
    "You can fully understand and follow the evaluation guidelines and evaluate the studies I have provided to you. Make sure all your judgments are based on the facts reported in the article and not on any extrapolation or speculation of your own.\n",
    "## Guidelines for Evaluation:\n",
    "**Note:** The examples provided do not cover all possible scenarios in real-world applications. So, use your expert judgment to evaluate each item based on the information provided in the study, and do not rely solely on the examples.\n",
    "### Important:\n",
    "- If there is too little information to support the judgment, do not speculate positively.\n",
    "- Reply with **ONLY** one of **Yes** or **No**. You provide reasoning behind each decision.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c94eb-6838-44e3-823f-2672151819dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_prompt = \"\"\"\n",
    "# Risk of Bias Assessment Criteria\n",
    "\n",
    "### 2.3) Sample Exclusion\n",
    "After the start of the intervention/exposure or during the analysis, were any subjects or areas excluded or lost from the study or analysis? When some subjects or areas, or collected data are excluded, it might increase the risk of post-intervention/exposure selection bias.\n",
    "Consider the following:\n",
    "- If the final participated sample is lower than the total potential participation sample, then respond with **yes**. \n",
    "- If the final participated sample is the same as the total potential participation sample, then respond with **no**.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20a626-a7e2-41c3-be24-a9bf5f5114bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = \"\"\"\n",
    "\n",
    "# Output Format\n",
    "\n",
    "Please output the result STRICTLY in the format below:\n",
    "\n",
    "{\n",
    "  \"explanation\": str,\n",
    "  \"result\": str\n",
    "}\n",
    "\n",
    "where explanation is a detailed reasoning that supports the decision, based on evidence from the document, and result is the overall decision for this item, respond only with one of ['yes', 'no'].\n",
    "\"\"\"\n",
    "\n",
    "intro_and_output = \"\\n\".join([intro_prompt, output_format])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f4d4d-88d4-4512-9305-f471d6a6bb5b",
   "metadata": {},
   "source": [
    "# Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db6f6b-ca27-411f-99bb-c1f8b6f013fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"files\"\n",
    "file_name = \"Houde, S; Todd, A; Sudarshan, A; Flora, JA; Armel, KC (2013).md\"\n",
    "\n",
    "with open(os.path.join(folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "    document = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eccb9d-4e7a-4759-b8ab-add87869f7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o',\n",
    "    temperature=0,\n",
    "    instructions=intro_prompt,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": f\"{criteria_prompt}\\n\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": f\"\\nHere is the paper:\\n{document}\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = response.output_text\n",
    "\n",
    "print(response_text)\n",
    "# data = json.loads(response_text)\n",
    "# parsed_response = AssessmentResultPerCriteria(**data)\n",
    "# print(f\"Result: {parsed_response.result}\\n\")\n",
    "# print(f\"Explanation: \\n {parsed_response.explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8bc10-770a-450b-a69c-79ac2c816d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser\n",
    "parsed = client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    instructions=f\"\"\"\n",
    "    Parse the following response into the provided schema. DO NOT change the content of the response.\n",
    "    \"\"\",\n",
    "    input=[{\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": f\"Response: {response_text}\"}]}],\n",
    "    text_format=AssessmentResultPerCriteria,\n",
    ")\n",
    "\n",
    "print(f\"Result: {parsed.output_parsed.result}\\n\")\n",
    "print(f\"Explanation: \\n {parsed.output_parsed.explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c94ad-de19-43b7-b5bc-81cc4ecb7bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
